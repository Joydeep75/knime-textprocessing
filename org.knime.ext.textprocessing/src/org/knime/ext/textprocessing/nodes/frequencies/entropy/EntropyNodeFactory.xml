<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE knimeNode PUBLIC "-//UNIKN//DTD KNIME Node 2.0//EN" "http://www.knime.org/Node.dtd">
<knimeNode icon="../../../icons/TextProcFrequencies.png" type="Learner">
    <name>Term Document Entropy</name>
    
    <shortDescription>
        This node computes the informational entropy of each term in each document. 
        If a term occurs once in every document, its entropy for each document is 0. 
        Any other combination of frequencies determines an entropy weight between 0 and 1.
    </shortDescription>
    
    <fullDescription>
    <intro>
        This node computes the informational entropy of each term in each document. 
        The nodes requires a bag of words table as input and appends an additional column to the output table, 
        containing the entropy values.
        If a term occurs once in every document, its entropy for each document is 0. 
        Any other combination of frequencies determines an entropy weight between 0 and 1.
        Please note, that the computational complexity of of the entropy calculation is greater than the number of terms
        times the number of documents. For big bag of words input tables the computation can be quite time consuming.
    </intro>
    <tab name="Document selection">
    <option name="Document Column">
       Specifies the document column to use for frequency counting.
    </option>
    </tab>

    </fullDescription>

    <ports>
        <inPort name="Terms and related documents input table" index="0">
        The input table which contains terms and documents.</inPort>
        <outPort name="Terms and documents output table" index="0">
        The output table with terms, documents and a corresponding
        entropy value.
        </outPort>
    </ports>

</knimeNode>
